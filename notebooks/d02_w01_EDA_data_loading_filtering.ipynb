{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5a481c",
   "metadata": {},
   "source": [
    "# Corporación Favorita Grocery Sales Forecasting\n",
    "## d02_w01_EDA_data_loading_filtering.ipynb\n",
    "\n",
    "**Author:** Alberto Diaz Durana  \n",
    "**Date:** November 2025  \n",
    "**Purpose:** Filter train.csv to Guayas region and top-3 families, create 300K sample for EDA\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook accomplishes the following:\n",
    "\n",
    "- Load train.csv with Dask and filter to Guayas stores (11 stores)\n",
    "- Merge with items.csv to get product family information\n",
    "- Filter to top-3 families: GROCERY I, BEVERAGES, CLEANING\n",
    "- Random sample 300,000 rows for development speed\n",
    "- Export filtered dataset as guayas_sample_300k.csv and .pkl\n",
    "- Validate filtering results and document reduction\n",
    "\n",
    "---\n",
    "\n",
    "## Business Context\n",
    "\n",
    "**Why this filtering matters:**\n",
    "\n",
    "Focusing on Guayas region and top-3 families enables:\n",
    "- Manageable dataset size (300K vs 125M rows)\n",
    "- Representative patterns (58.4% of items, 20.4% of stores)\n",
    "- Faster iteration during EDA and modeling\n",
    "- Regional insights for Guayas market specifically\n",
    "\n",
    "**Filtering criteria:**\n",
    "- Guayas stores: 11 of 54 (store IDs: 24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 51)\n",
    "- Top-3 families: GROCERY I (1,334 items), BEVERAGES (613 items), CLEANING (446 items)\n",
    "- Sample: 300,000 random rows (reproducible with seed=42)\n",
    "\n",
    "**Deliverables:**\n",
    "- guayas_sample_300k.csv (300K rows, filtered dataset)\n",
    "- guayas_sample_300k.pkl (faster loading for Day 3)\n",
    "- Filtering validation report\n",
    "\n",
    "---\n",
    "\n",
    "## Input Dependencies\n",
    "\n",
    "From Day 1:\n",
    "- train.csv (125,497,040 rows)\n",
    "- stores.csv (54 stores)\n",
    "- items.csv (4,100 items)\n",
    "- Guayas store list: [24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 51]\n",
    "- Top-3 families: ['GROCERY I', 'BEVERAGES', 'CLEANING']\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa601ce",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "**Objective:** Import libraries, load support files from Day 1, configure paths\n",
    "\n",
    "**Activities:**\n",
    "- Import pandas, dask, numpy\n",
    "- Load inventory results from Day 1 (stores, items)\n",
    "- Define path constants\n",
    "- Set random seed for reproducibility\n",
    "\n",
    "**Expected output:** Environment ready, support files reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab77bb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package Versions:\n",
      "  pandas: 2.1.4\n",
      "  numpy: 1.26.4\n",
      "  dask: 2025.11.0\n",
      "\n",
      "OK - Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Package versions\n",
    "print(\"Package Versions:\")\n",
    "print(f\"  pandas: {pd.__version__}\")\n",
    "print(f\"  numpy: {np.__version__}\")\n",
    "print(f\"  dask: {dask.__version__}\")\n",
    "\n",
    "# Configure environment\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"\\nOK - Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3cd971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Paths validated:\n",
      "  Project root: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\n",
      "  DATA_RAW: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\data\\raw\n",
      "  DATA_PROCESSED: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\data\\processed\n",
      "\n",
      "Random seed set: 42\n"
     ]
    }
   ],
   "source": [
    "# Determine paths (works from notebooks/ or project root)\n",
    "current_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "\n",
    "# Define path constants\n",
    "DATA_RAW = project_root / 'data' / 'raw'\n",
    "DATA_PROCESSED = project_root / 'data' / 'processed'\n",
    "\n",
    "# Verify paths exist\n",
    "assert DATA_RAW.exists(), f\"ERROR - Path not found: {DATA_RAW}\"\n",
    "assert DATA_PROCESSED.exists(), f\"ERROR - Path not found: {DATA_PROCESSED}\"\n",
    "\n",
    "print(\"OK - Paths validated:\")\n",
    "print(f\"  Project root: {project_root.resolve()}\")\n",
    "print(f\"  DATA_RAW: {DATA_RAW.resolve()}\")\n",
    "print(f\"  DATA_PROCESSED: {DATA_PROCESSED.resolve()}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(f\"\\nRandom seed set: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a656e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading support files...\n",
      "✓ stores.csv: 54 stores\n",
      "✓ items.csv: 4100 items\n",
      "\n",
      "Guayas scope defined:\n",
      "  Stores: 11 stores\n",
      "  Store IDs: [24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 51]\n",
      "  Families: ['GROCERY I', 'BEVERAGES', 'CLEANING']\n",
      "  Items in top-3 families: 2,393\n",
      "\n",
      "OK - Support files loaded and scope defined\n"
     ]
    }
   ],
   "source": [
    "# Load support files from Day 1\n",
    "print(\"Loading support files...\")\n",
    "\n",
    "df_stores = pd.read_csv(DATA_RAW / 'stores.csv')\n",
    "df_items = pd.read_csv(DATA_RAW / 'items.csv')\n",
    "\n",
    "print(f\"✓ stores.csv: {len(df_stores)} stores\")\n",
    "print(f\"✓ items.csv: {len(df_items)} items\")\n",
    "\n",
    "# Define Guayas scope (from Day 1 analysis)\n",
    "guayas_store_nbrs = [24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 51]\n",
    "top_3_families = ['GROCERY I', 'BEVERAGES', 'CLEANING']\n",
    "\n",
    "print(f\"\\nGuayas scope defined:\")\n",
    "print(f\"  Stores: {len(guayas_store_nbrs)} stores\")\n",
    "print(f\"  Store IDs: {guayas_store_nbrs}\")\n",
    "print(f\"  Families: {top_3_families}\")\n",
    "\n",
    "# Verify items in top-3 families\n",
    "top_3_items = df_items[df_items['family'].isin(top_3_families)]\n",
    "print(f\"  Items in top-3 families: {len(top_3_items):,}\")\n",
    "\n",
    "print(\"\\nOK - Support files loaded and scope defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e150170",
   "metadata": {},
   "source": [
    "## 2. Load & Filter train.csv to Guayas\n",
    "\n",
    "**Objective:** Load large train.csv with Dask and filter to Guayas stores only\n",
    "\n",
    "**Activities:**\n",
    "- Load train.csv with Dask (125M rows)\n",
    "- Filter to 11 Guayas stores\n",
    "- Convert filtered result to pandas\n",
    "- Validate row count reduction\n",
    "- Check memory usage\n",
    "\n",
    "**Expected output:** \n",
    "- Filtered dataset with ~25M rows (20% of original)\n",
    "- Pandas DataFrame ready for further filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36f02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv with Dask (125M rows)...\n",
      "This may take 1-2 minutes...\n",
      "\n",
      "OK - train.csv loaded (Dask DataFrame)\n",
      "  Columns: ['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion']\n",
      "  Estimated rows: 125,497,040\n"
     ]
    }
   ],
   "source": [
    "# Load train.csv with Dask\n",
    "print(\"Loading train.csv with Dask (125M rows)...\")\n",
    "print(\"This may take 1-2 minutes...\\n\")\n",
    "\n",
    "df_train = dd.read_csv(DATA_RAW / 'train.csv')\n",
    "\n",
    "print(f\"OK - train.csv loaded (Dask DataFrame)\")\n",
    "print(f\"  Columns: {list(df_train.columns)}\")\n",
    "print(f\"  Estimated rows: 125,497,040\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23031069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering to Guayas stores (11 stores)...\n",
      "This will take 2-3 minutes - processing 125M rows...\n",
      "\n",
      "Computing filtered dataset...\n",
      "\n",
      "OK - Filtering complete!\n",
      "  Original rows: 125,497,040\n",
      "  Filtered rows: 22,941,656\n",
      "  Reduction: 81.7%\n",
      "  Memory usage: 1356.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Filter to Guayas stores only\n",
    "print(\"Filtering to Guayas stores (11 stores)...\")\n",
    "print(\"This will take 2-3 minutes - processing 125M rows...\\n\")\n",
    "\n",
    "df_train_guayas = df_train[df_train['store_nbr'].isin(guayas_store_nbrs)]\n",
    "\n",
    "print(\"Computing filtered dataset...\")\n",
    "df_train_guayas = df_train_guayas.compute()\n",
    "\n",
    "print(f\"\\nOK - Filtering complete!\")\n",
    "print(f\"  Original rows: 125,497,040\")\n",
    "print(f\"  Filtered rows: {len(df_train_guayas):,}\")\n",
    "print(f\"  Reduction: {(1 - len(df_train_guayas)/125497040)*100:.1f}%\")\n",
    "print(f\"  Memory usage: {df_train_guayas.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea76089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of Guayas-filtered data:\n",
      "          id        date  store_nbr  item_nbr  unit_sales  onpromotion\n",
      "18789  18789  2013-01-02         24    103665        6.00          NaN\n",
      "18790  18790  2013-01-02         24    105574       12.00          NaN\n",
      "18791  18791  2013-01-02         24    105575        2.00          NaN\n",
      "18792  18792  2013-01-02         24    105577        1.00          NaN\n",
      "18793  18793  2013-01-02         24    105693        7.00          NaN\n",
      "\n",
      "Data types:\n",
      "id                       int64\n",
      "date           string[pyarrow]\n",
      "store_nbr                int64\n",
      "item_nbr                 int64\n",
      "unit_sales             float64\n",
      "onpromotion            float64\n",
      "dtype: object\n",
      "\n",
      "Unique stores in filtered data:\n",
      "[24, 26, 27, 28, 29, 30, 32, 34, 35, 36, 51]\n",
      "\n",
      "Unique items in filtered data:\n",
      "  Total unique items: 4,008\n"
     ]
    }
   ],
   "source": [
    "# Display first rows and basic info\n",
    "print(\"First 5 rows of Guayas-filtered data:\")\n",
    "print(df_train_guayas.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df_train_guayas.dtypes)\n",
    "\n",
    "print(\"\\nUnique stores in filtered data:\")\n",
    "print(sorted(df_train_guayas['store_nbr'].unique()))\n",
    "\n",
    "print(\"\\nUnique items in filtered data:\")\n",
    "print(f\"  Total unique items: {df_train_guayas['item_nbr'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fa222",
   "metadata": {},
   "source": [
    "## 3. Filter to Top-3 Families & Sample 300K\n",
    "\n",
    "**Objective:** Merge with items, filter to top-3 families, sample 300K rows\n",
    "\n",
    "**Activities:**\n",
    "- Merge train data with items.csv to get family column\n",
    "- Filter to top-3 families: GROCERY I, BEVERAGES, CLEANING\n",
    "- Random sample 300,000 rows (seed=42 for reproducibility)\n",
    "- Validate final dataset characteristics\n",
    "\n",
    "**Expected output:** \n",
    "- Final dataset: 300,000 rows\n",
    "- Guayas stores + top-3 families only\n",
    "- Representative sample of filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d30885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging with items.csv to get product family...\n",
      "OK - Merge complete\n",
      "  Rows after merge: 22,941,656\n",
      "  Columns: ['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion', 'family', 'class', 'perishable']\n",
      "  Rows with missing family: 0\n"
     ]
    }
   ],
   "source": [
    "# Merge with items to get family information\n",
    "print(\"Merging with items.csv to get product family...\")\n",
    "\n",
    "df_train_merged = df_train_guayas.merge(\n",
    "    df_items[['item_nbr', 'family', 'class', 'perishable']], \n",
    "    on='item_nbr', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"OK - Merge complete\")\n",
    "print(f\"  Rows after merge: {len(df_train_merged):,}\")\n",
    "print(f\"  Columns: {list(df_train_merged.columns)}\")\n",
    "\n",
    "# Check for merge issues\n",
    "null_families = df_train_merged['family'].isnull().sum()\n",
    "print(f\"  Rows with missing family: {null_families}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5066f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering to top-3 families...\n",
      "  Families to keep: ['GROCERY I', 'BEVERAGES', 'CLEANING']\n",
      "\n",
      "OK - Filtering complete\n",
      "  Rows before family filter: 22,941,656\n",
      "  Rows after family filter: 14,745,768\n",
      "  Reduction: 35.7%\n",
      "\n",
      "Family distribution in filtered data:\n",
      "family\n",
      "GROCERY I    8398042\n",
      "BEVERAGES    3249089\n",
      "CLEANING     3098637\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage by family:\n",
      "  GROCERY I        8,398,042 ( 57.0%)\n",
      "  BEVERAGES        3,249,089 ( 22.0%)\n",
      "  CLEANING         3,098,637 ( 21.0%)\n"
     ]
    }
   ],
   "source": [
    "# Filter to top-3 families\n",
    "print(\"Filtering to top-3 families...\")\n",
    "print(f\"  Families to keep: {top_3_families}\\n\")\n",
    "\n",
    "df_train_top3 = df_train_merged[df_train_merged['family'].isin(top_3_families)].copy()\n",
    "\n",
    "print(f\"OK - Filtering complete\")\n",
    "print(f\"  Rows before family filter: {len(df_train_merged):,}\")\n",
    "print(f\"  Rows after family filter: {len(df_train_top3):,}\")\n",
    "print(f\"  Reduction: {(1 - len(df_train_top3)/len(df_train_merged))*100:.1f}%\")\n",
    "\n",
    "print(\"\\nFamily distribution in filtered data:\")\n",
    "family_counts = df_train_top3['family'].value_counts()\n",
    "print(family_counts)\n",
    "\n",
    "print(\"\\nPercentage by family:\")\n",
    "for family, count in family_counts.items():\n",
    "    pct = count / len(df_train_top3) * 100\n",
    "    print(f\"  {family:<15} {count:>10,} ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cf5845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 300,000 random rows...\n",
      "  Random seed: 42\n",
      "  Sample fraction: 2.034%\n",
      "\n",
      "OK - Sampling complete\n",
      "  Sample size: 300,000 rows\n",
      "  Columns: 9\n",
      "  Memory usage: 36.6 MB\n",
      "\n",
      "Family distribution in sample:\n",
      "  GROCERY I       170,594 ( 56.9%)\n",
      "  BEVERAGES        66,147 ( 22.0%)\n",
      "  CLEANING         63,259 ( 21.1%)\n"
     ]
    }
   ],
   "source": [
    "# Random sample 300,000 rows\n",
    "print(\"Sampling 300,000 random rows...\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "print(f\"  Sample fraction: {300000/len(df_train_top3)*100:.3f}%\\n\")\n",
    "\n",
    "df_sample = df_train_top3.sample(n=300000, random_state=RANDOM_SEED).copy()\n",
    "\n",
    "# Reset index for clean sequential numbering\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "\n",
    "print(f\"OK - Sampling complete\")\n",
    "print(f\"  Sample size: {len(df_sample):,} rows\")\n",
    "print(f\"  Columns: {len(df_sample.columns)}\")\n",
    "print(f\"  Memory usage: {df_sample.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "print(\"\\nFamily distribution in sample:\")\n",
    "sample_family_counts = df_sample['family'].value_counts()\n",
    "for family, count in sample_family_counts.items():\n",
    "    pct = count / len(df_sample) * 100\n",
    "    print(f\"  {family:<15} {count:>7,} ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df0075a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset overview:\n",
      "\n",
      "First 5 rows:\n",
      "         id        date  store_nbr  item_nbr  unit_sales  onpromotion  \\\n",
      "0  86626618  2016-07-31         32   1395693        1.00         0.00   \n",
      "1  53995064  2015-08-15         24   1464210       30.00         0.00   \n",
      "2  21834951  2014-04-04         27   1102970        1.00         0.00   \n",
      "3  14853390  2013-12-02         26   1162382       20.00          NaN   \n",
      "4  14652646  2013-11-28         34    577741        2.00          NaN   \n",
      "\n",
      "      family  class  perishable  \n",
      "0  GROCERY I   1028           0  \n",
      "1  BEVERAGES   1114           0  \n",
      "2  BEVERAGES   1122           0  \n",
      "3  GROCERY I   1022           0  \n",
      "4  GROCERY I   1032           0  \n",
      "\n",
      "Last 5 rows:\n",
      "               id        date  store_nbr  item_nbr  unit_sales  onpromotion  \\\n",
      "299995   29636439  2014-08-25         27    219147        4.00         0.00   \n",
      "299996  117116855  2017-05-28         34   1463770        2.00         0.00   \n",
      "299997   30368924  2014-09-06         26    269287       15.00         0.00   \n",
      "299998   96692477  2016-11-12         28   1146802       21.00         0.00   \n",
      "299999   77332954  2016-04-25         24    692104        6.00         0.00   \n",
      "\n",
      "           family  class  perishable  \n",
      "299995  BEVERAGES   1122           0  \n",
      "299996  BEVERAGES   1114           0  \n",
      "299997   CLEANING   3014           0  \n",
      "299998  GROCERY I   1040           0  \n",
      "299999   CLEANING   3014           0  \n",
      "\n",
      "Basic statistics for unit_sales:\n",
      "count   300000.00\n",
      "mean         6.79\n",
      "std         15.64\n",
      "min        -92.00\n",
      "25%          2.00\n",
      "50%          3.00\n",
      "75%          7.00\n",
      "max       2534.00\n",
      "Name: unit_sales, dtype: float64\n",
      "\n",
      "Stores in sample:\n",
      "  Unique stores: 11\n",
      "  All 11 Guayas stores present: True\n",
      "\n",
      "Date range in sample:\n",
      "  First date: 2013-01-02\n",
      "  Last date: 2017-08-15\n"
     ]
    }
   ],
   "source": [
    "# Display sample characteristics\n",
    "print(\"Sample dataset overview:\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_sample.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(df_sample.tail())\n",
    "\n",
    "print(\"\\nBasic statistics for unit_sales:\")\n",
    "print(df_sample['unit_sales'].describe())\n",
    "\n",
    "print(\"\\nStores in sample:\")\n",
    "store_counts = df_sample['store_nbr'].value_counts().sort_index()\n",
    "print(f\"  Unique stores: {df_sample['store_nbr'].nunique()}\")\n",
    "print(f\"  All 11 Guayas stores present: {set(df_sample['store_nbr'].unique()) == set(guayas_store_nbrs)}\")\n",
    "\n",
    "print(\"\\nDate range in sample:\")\n",
    "print(f\"  First date: {df_sample['date'].min()}\")\n",
    "print(f\"  Last date: {df_sample['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a5235",
   "metadata": {},
   "source": [
    "## 4. Export & Validate\n",
    "\n",
    "**Objective:** Save filtered sample and create validation summary\n",
    "\n",
    "**Activities:**\n",
    "- Export to CSV (guayas_sample_300k.csv)\n",
    "- Export to pickle (guayas_sample_300k.pkl) for faster loading\n",
    "- Create filtering summary report\n",
    "- Document data quality observations\n",
    "\n",
    "**Expected output:** \n",
    "- Two export files in data/processed/\n",
    "- Validation report confirming scope and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0948347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to CSV: guayas_sample_300k.csv\n",
      "  ✓ CSV saved (16.0 MB)\n",
      "\n",
      "Exporting to pickle: guayas_sample_300k.pkl\n",
      "  ✓ Pickle saved (20.6 MB)\n",
      "\n",
      "OK - Export complete\n",
      "  CSV: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\data\\processed\\guayas_sample_300k.csv\n",
      "  Pickle: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\data\\processed\\guayas_sample_300k.pkl\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "csv_path = DATA_PROCESSED / 'guayas_sample_300k.csv'\n",
    "print(f\"Exporting to CSV: {csv_path.name}\")\n",
    "df_sample.to_csv(csv_path, index=False)\n",
    "print(f\"  ✓ CSV saved ({csv_path.stat().st_size / 1024**2:.1f} MB)\")\n",
    "\n",
    "# Export to pickle (faster loading)\n",
    "pkl_path = DATA_PROCESSED / 'guayas_sample_300k.pkl'\n",
    "print(f\"\\nExporting to pickle: {pkl_path.name}\")\n",
    "df_sample.to_pickle(pkl_path)\n",
    "print(f\"  ✓ Pickle saved ({pkl_path.stat().st_size / 1024**2:.1f} MB)\")\n",
    "\n",
    "print(\"\\nOK - Export complete\")\n",
    "print(f\"  CSV: {csv_path.resolve()}\")\n",
    "print(f\"  Pickle: {pkl_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a202812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERING SUMMARY\n",
      "======================================================================\n",
      "original_rows                  125497040\n",
      "after_guayas_filter            22941656\n",
      "after_family_filter            14745768\n",
      "final_sample                   300000\n",
      "guayas_stores                  11\n",
      "top_3_families                 3\n",
      "unique_items_in_sample         2296\n",
      "date_range_start               2013-01-02\n",
      "date_range_end                 2017-08-15\n",
      "missing_onpromotion            55706\n",
      "missing_onpromotion_pct        18.57%\n",
      "negative_sales_count           13\n",
      "negative_sales_pct             0.00%\n",
      "\n",
      "======================================================================\n",
      "DATA REDUCTION PIPELINE:\n",
      "  125,497,040 rows (original)\n",
      "  → 22,941,656 rows (Guayas filter, -81.7%)\n",
      "  → 14,745,768 rows (top-3 families, -35.7%)\n",
      "  → 300,000 rows (random sample, -98.0%)\n",
      "  Final: 0.24% of original dataset\n"
     ]
    }
   ],
   "source": [
    "# Create filtering summary report\n",
    "filtering_summary = {\n",
    "    'original_rows': 125_497_040,\n",
    "    'after_guayas_filter': 22_941_656,\n",
    "    'after_family_filter': 14_745_768,\n",
    "    'final_sample': 300_000,\n",
    "    'guayas_stores': len(guayas_store_nbrs),\n",
    "    'top_3_families': len(top_3_families),\n",
    "    'unique_items_in_sample': df_sample['item_nbr'].nunique(),\n",
    "    'date_range_start': str(df_sample['date'].min()),\n",
    "    'date_range_end': str(df_sample['date'].max()),\n",
    "    'missing_onpromotion': df_sample['onpromotion'].isnull().sum(),\n",
    "    'missing_onpromotion_pct': f\"{df_sample['onpromotion'].isnull().sum() / len(df_sample) * 100:.2f}%\",\n",
    "    'negative_sales_count': (df_sample['unit_sales'] < 0).sum(),\n",
    "    'negative_sales_pct': f\"{(df_sample['unit_sales'] < 0).sum() / len(df_sample) * 100:.2f}%\",\n",
    "}\n",
    "\n",
    "print(\"FILTERING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "for key, value in filtering_summary.items():\n",
    "    print(f\"{key:<30} {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA REDUCTION PIPELINE:\")\n",
    "print(f\"  125,497,040 rows (original)\")\n",
    "print(f\"  → 22,941,656 rows (Guayas filter, -81.7%)\")\n",
    "print(f\"  → 14,745,768 rows (top-3 families, -35.7%)\")\n",
    "print(f\"  → 300,000 rows (random sample, -98.0%)\")\n",
    "print(f\"  Final: 0.24% of original dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86de9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA QUALITY VALIDATION\n",
      "======================================================================\n",
      "✓ All 11 Guayas stores present: True\n",
      "✓ Only top-3 families present: True\n",
      "✓ No duplicate rows: True (duplicates: 0)\n",
      "✓ All required columns present: True\n",
      "✓ Date range covers 5 years (2013-2017)\n",
      "✓ Memory usage: 36.6 MB (manageable for analysis)\n",
      "\n",
      "======================================================================\n",
      "VALIDATION COMPLETE - Dataset ready for EDA (Day 3)\n"
     ]
    }
   ],
   "source": [
    "# Data quality validation checks\n",
    "print(\"DATA QUALITY VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check 1: All Guayas stores present\n",
    "all_stores_present = set(df_sample['store_nbr'].unique()) == set(guayas_store_nbrs)\n",
    "print(f\"✓ All 11 Guayas stores present: {all_stores_present}\")\n",
    "\n",
    "# Check 2: Only top-3 families\n",
    "only_top3 = set(df_sample['family'].unique()) == set(top_3_families)\n",
    "print(f\"✓ Only top-3 families present: {only_top3}\")\n",
    "\n",
    "# Check 3: No duplicate rows\n",
    "no_duplicates = df_sample.duplicated().sum() == 0\n",
    "print(f\"✓ No duplicate rows: {no_duplicates} (duplicates: {df_sample.duplicated().sum()})\")\n",
    "\n",
    "# Check 4: All required columns present\n",
    "required_cols = ['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion', 'family', 'class', 'perishable']\n",
    "all_cols_present = all(col in df_sample.columns for col in required_cols)\n",
    "print(f\"✓ All required columns present: {all_cols_present}\")\n",
    "\n",
    "# Check 5: Date range coverage\n",
    "date_range_years = pd.to_datetime(df_sample['date']).dt.year.nunique()\n",
    "print(f\"✓ Date range covers {date_range_years} years (2013-2017)\")\n",
    "\n",
    "# Check 6: Memory efficiency\n",
    "memory_mb = df_sample.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"✓ Memory usage: {memory_mb:.1f} MB (manageable for analysis)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VALIDATION COMPLETE - Dataset ready for EDA (Day 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e44b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NOTEBOOK COMPLETE: d02_w01_EDA_data_loading_filtering.ipynb\n",
      "======================================================================\n",
      "\n",
      "ACCOMPLISHMENTS:\n",
      "✓ Loaded train.csv (125M rows) with Dask\n",
      "✓ Filtered to Guayas region (11 stores, 22.9M rows)\n",
      "✓ Filtered to top-3 families (14.7M rows)\n",
      "✓ Random sampled 300K rows (seed=42, reproducible)\n",
      "✓ Exported CSV and pickle to data/processed/\n",
      "\n",
      "FILES CREATED:\n",
      "  - guayas_sample_300k.csv (16.0 MB)\n",
      "  - guayas_sample_300k.pkl (20.6 MB)\n",
      "\n",
      "KEY CHARACTERISTICS:\n",
      "  Rows: 300,000\n",
      "  Stores: 11 (Guayas region)\n",
      "  Families: 3 (GROCERY I 56.9%, BEVERAGES 22.0%, CLEANING 21.1%)\n",
      "  Items: 2,296 unique\n",
      "  Date range: 2013-01-02 to 2017-08-15 (5 years)\n",
      "  Missing onpromotion: 18.57% (55,706 rows)\n",
      "  Negative sales: 13 rows (0.00%)\n",
      "\n",
      "DATA QUALITY NOTES:\n",
      "  → onpromotion NaN values: Will fill with False in Day 3\n",
      "  → Negative unit_sales: Will clip to 0 in Day 3\n",
      "  → Date column: String type, convert to datetime in Day 3\n",
      "  → Missing dates: Calendar gaps to fill in Day 3\n",
      "\n",
      "NEXT STEPS (Day 3):\n",
      "  1. Load guayas_sample_300k.pkl\n",
      "  2. Handle missing onpromotion values (fill False)\n",
      "  3. Clip negative unit_sales to 0\n",
      "  4. Fill calendar gaps (complete daily index)\n",
      "  5. Outlier detection and analysis\n",
      "\n",
      "READY FOR DAY 3 - EDA Part 1: Quality & Preprocessing ✓\n"
     ]
    }
   ],
   "source": [
    "# Notebook completion summary\n",
    "print(\"=\" * 70)\n",
    "print(\"NOTEBOOK COMPLETE: d02_w01_EDA_data_loading_filtering.ipynb\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nACCOMPLISHMENTS:\")\n",
    "print(\"✓ Loaded train.csv (125M rows) with Dask\")\n",
    "print(\"✓ Filtered to Guayas region (11 stores, 22.9M rows)\")\n",
    "print(\"✓ Filtered to top-3 families (14.7M rows)\")\n",
    "print(\"✓ Random sampled 300K rows (seed=42, reproducible)\")\n",
    "print(\"✓ Exported CSV and pickle to data/processed/\")\n",
    "\n",
    "print(\"\\nFILES CREATED:\")\n",
    "print(f\"  - guayas_sample_300k.csv (16.0 MB)\")\n",
    "print(f\"  - guayas_sample_300k.pkl (20.6 MB)\")\n",
    "\n",
    "print(\"\\nKEY CHARACTERISTICS:\")\n",
    "print(f\"  Rows: 300,000\")\n",
    "print(f\"  Stores: 11 (Guayas region)\")\n",
    "print(f\"  Families: 3 (GROCERY I 56.9%, BEVERAGES 22.0%, CLEANING 21.1%)\")\n",
    "print(f\"  Items: 2,296 unique\")\n",
    "print(f\"  Date range: 2013-01-02 to 2017-08-15 (5 years)\")\n",
    "print(f\"  Missing onpromotion: 18.57% (55,706 rows)\")\n",
    "print(f\"  Negative sales: 13 rows (0.00%)\")\n",
    "\n",
    "print(\"\\nDATA QUALITY NOTES:\")\n",
    "print(\"  → onpromotion NaN values: Will fill with False in Day 3\")\n",
    "print(\"  → Negative unit_sales: Will clip to 0 in Day 3\")\n",
    "print(\"  → Date column: String type, convert to datetime in Day 3\")\n",
    "print(\"  → Missing dates: Calendar gaps to fill in Day 3\")\n",
    "\n",
    "print(\"\\nNEXT STEPS (Day 3):\")\n",
    "print(\"  1. Load guayas_sample_300k.pkl\")\n",
    "print(\"  2. Handle missing onpromotion values (fill False)\")\n",
    "print(\"  3. Clip negative unit_sales to 0\")\n",
    "print(\"  4. Fill calendar gaps (complete daily index)\")\n",
    "print(\"  5. Outlier detection and analysis\")\n",
    "\n",
    "print(\"\\nREADY FOR DAY 3 - EDA Part 1: Quality & Preprocessing ✓\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
